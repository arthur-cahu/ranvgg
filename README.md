# Synthèse de textures par réseau convolutif (filtres aléatoires)

Le notebook `main.ipynb` présente quelques approches permettant de synthétiser des textures à partir d'un exemple.

Réalisé dans le cadre du [cours d'introduction à l'imagerie numérique](https://perso.telecom-paristech.fr/gousseau/MVA/) de Julie Delon et Yann Gousseau.

## Sources

- Article initial de Leon A. Gatys, Alexander S. Ecker et Matthias Bethge: [Texture Synthesis Using Convolutional Neural Networks](https://papers.nips.cc/paper/5633-texture-synthesis-using-convolutional-neural-networks)

  - [Code de Gatys *et. al*](https://github.com/leongatys/DeepTextures)

  - [Ré-implémentation PyTorch](https://github.com/trsvchn/deep-textures)

  - [Jupyter notebook](https://github.com/bgalerne/mva_generative_models_for_images/blob/9f95b467360239257c5bf48fcd28e3189b30176a/2_mvagm_CNN_texture_synthesis.ipynb) de [Bruno Galerne](https://github.com/bgalerne) et Lucía Bouza
- Modifié selon l'article de Kun He, Yan Wang et John E. Hopcroft: [A Powerful Generative Model Using Random Weights for the Deep Image Representation](https://arxiv.org/abs/1606.04801)