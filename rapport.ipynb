{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthèse de textures par réseau convolutif (filtres aléatoires)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "import os\n",
    "\n",
    "from utils import prep_img, denormalize, to_pil, randomize_layer_, randomize_model_, register_model_hooks, unregister_model_hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch images\n",
    "texture_imgnames = [\"bois.png\", \"briques.png\", \"mur.png\",\n",
    "                    \"tissu.png\", \"nuages.png\", \"pebbles.jpg\", \"wall1003.png\"]\n",
    "#TODO use urllib instead \n",
    "#import wget\n",
    "for fname in texture_imgnames:\n",
    "    os.system(\"wget -c https://www.idpoisson.fr/galerne/mva/\" + fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device is\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ranVGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO description de VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps, nous chargeons le modèle VGG pré-entraîné afin d'évaluer notre implémentation sur un réseau dont les poids sont déjà optimisés:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.vgg19(pretrained=True).features.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO description théorique  de la content loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(cnn: nn.Module, layer_output_: \"list[torch.Tensor]\", target_out: torch.Tensor, synthetic_image: \"torch.Tensor\", weighing_factor: float = None):\n",
    "    # uses the layer_output variable to get the output of the target layer\n",
    "    # assumes correctly batched input (ie bchw dimensions)\n",
    "    # assumes target of shape chw\n",
    "    # make sure to un/register hooks before/after content_loss, using relu output\n",
    "    # suitable to use inside a closure (see https://pytorch.org/docs/stable/optim.html)\n",
    "\n",
    "    # step 1: forward-propagate and get the layer output from the mutable\n",
    "    cnn(synthetic_image)\n",
    "    synth_out = layer_output_[0] # add batch dimension\n",
    "    \n",
    "    # step 2: compute the loss\n",
    "    n_feature_maps, feature_height, feature_width = synth_out.shape\n",
    "    loss = F.mse_loss(synth_out, target_out)\n",
    "\n",
    "    if weighing_factor is not None:\n",
    "        loss *= weighing_factor\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO description de la reconstruction d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_image(cnn: nn.Module, target_image: torch.Tensor, target_layer_idx: int, n_steps: int = 10, synth_std: float = 0.5):\n",
    "    # return reconstructed image and final loss\n",
    "\n",
    "    # on initialise la pré-umage avec un bruit blanc:\n",
    "    synthetic_image = torch.normal(\n",
    "        0,\n",
    "        synth_std,\n",
    "        target_image.shape,\n",
    "        device=target_image.device,\n",
    "        requires_grad=True\n",
    "    )\n",
    "\n",
    "    layer_output_, handles = register_model_hooks(cnn, [target_layer_idx])\n",
    "\n",
    "    # le réseau ne va pas être modifié, donc on peut calculer la cible une fois pour toutes:\n",
    "    cnn(target_image)\n",
    "    target_out = torch.clone(layer_output_[0].detach()) # on considère la cible comme une vérité terrain\n",
    "\n",
    "    optimizer = optim.LBFGS([synthetic_image], max_iter=20)\n",
    "\n",
    "    loss_history = []\n",
    "\n",
    "    for iter in range(n_steps):\n",
    "\n",
    "        def closure():\n",
    "            # zero out the gradients, else they'll accumulate in synthetic_image.grad\n",
    "            optimizer.zero_grad()\n",
    "            loss = content_loss(cnn, layer_output_, target_out, synthetic_image)\n",
    "            loss.backward()  # backpropagate the loss to the input\n",
    "            loss_history.append(loss.item())\n",
    "            return loss\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "    final_loss = content_loss(cnn, layer_output_, target_out, synthetic_image)\n",
    "\n",
    "    unregister_model_hooks(handles)\n",
    "\n",
    "    return synthetic_image, final_loss, loss_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons la reconstruction d'image; He *et al.* comparent leurs résultats aux sorties des couches de pooling de VGG, et nous allons donc utiliser la couche pooling3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_name = \"briques.png\"\n",
    "img_size = 512\n",
    "target_layer = 18  # pool3\n",
    "\n",
    "target_image = prep_img(input_image_name, img_size).to(device)\n",
    "synthetic_image, loss, loss_history = reconstruct_image(\n",
    "    cnn,\n",
    "    target_image,\n",
    "    target_layer,\n",
    "    n_steps=100\n",
    ")\n",
    "\n",
    "fig, _ = plt.subplots(1, 2, figsize=(15, 10))\n",
    "fig.axes[0].imshow(to_pil(target_image))\n",
    "fig.axes[0].set_title(\"Original\")\n",
    "fig.axes[1].imshow(to_pil(synthetic_image))\n",
    "fig.axes[1].set_title(\"Reconstruction\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous arrivons bien à reconstruire l'image d'origine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss history\n",
    "fig, _ = plt.subplots(1, 1, figsize=(15, 10))\n",
    "fig.axes[0].plot(loss_history)\n",
    "fig.axes[0].set_xlabel(\"L-BFGS iterations\")\n",
    "fig.axes[0].set_ylabel(\"Content loss\")\n",
    "fig.axes[0].set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au vu de la courbe ci-dessus, la fonction de perte semble converger pour VGG autour de 100 itérations de L-BGFS; nous avons donc choisi `n_steps = 10` par défaut, ce qui correspond à 200 itérations de L-BFGS (`optim.LBFGS` effectue par défaut 20 itérations par étape)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction de ranVGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO stuff below here is for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gramm(tnsr: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Computes Gram matrix for the input batch tensor.\n",
    "    Args: tnsr (torch.Tensor): input tensor of the Size([B, C, H, W]).\n",
    "    Returns:  G (torch.Tensor): output tensor of the Size([B, C, C]).\n",
    "    \"\"\"\n",
    "    b, c, h, w = tnsr.size()\n",
    "    F = tnsr.view(b, c, h * w)\n",
    "    G = torch.bmm(F, F.transpose(1, 2))\n",
    "    G.div_(h * w)\n",
    "    return G\n",
    "\n",
    "\n",
    "def gram_loss(input: torch.Tensor, gramm_target: torch.Tensor, weight: float = 1.0):\n",
    "    \"\"\"Computes the MSE loss between the Gram matrix of the input and the target\n",
    "    Gram matrix. \n",
    "    \"\"\"\n",
    "    loss = weight * F.mse_loss(gramm(input), gramm_target)\n",
    "    return loss\n",
    "\n",
    "\n",
    "#TODO define texture_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ranvgg_(cnn, img, n_samples=1000):\n",
    "    # remplacement des poids du modèle par un bruit blanc:\n",
    "    randomize_model_(cnn)\n",
    "    cnn.requires_grad_(False)  # on empêche le modèle d'apprendre\n",
    "    layers_to_build = [\n",
    "        idx for idx, layer in enumerate(cnn) if isinstance(layer, nn.Conv2d)\n",
    "    ]\n",
    "    # on enregistre la sortie des couches qu'on construit\n",
    "    outputs, handles = register_model_hooks(cnn, layers_to_build)\n",
    "    # TODO do stuff here\n",
    "    \n",
    "    unregister_model_hooks(handles)  # on enlève les handles du modèle\n",
    "    return cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers to use in the texture synthesis:\n",
    "TARGET_LAYERS = [1, 4, 9, 18, 27]  # 1rst Conv2d (after ReLU) and MaxPool2d\n",
    "LAYER_NAMES = [\"conv1\", \"pool1\", \"pool2\", \"pool3\", \"pool4\"]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec098f3f8c662b53cb495a99f3bdf670fa1052aa811a9729b1f28e0384e8235b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
