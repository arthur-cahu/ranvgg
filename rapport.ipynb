{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRBDQgzFoF0B"
   },
   "source": [
    "# Synthèse de textures par réseau convolutif (filtres aléatoires)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXG59cnxoF0F"
   },
   "source": [
    "## Mise en Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCUwrEdAoF0G"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rCFnFBcSoF0I"
   },
   "outputs": [],
   "source": [
    "# fetch images\n",
    "texture_imgnames = [\"bois.png\", \"briques.png\", \"mur.png\",\n",
    "                    \"tissu.png\", \"nuages.png\", \"pebbles.jpg\", \"wall1003.png\"]\n",
    "#TODO use urllib instead \n",
    "#import wget\n",
    "for fname in texture_imgnames:\n",
    "    os.system(\"wget -c https://www.idpoisson.fr/galerne/mva/\" + fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_tmjXWHoF0L",
    "outputId": "d564164c-0cf2-4f69-bc11-2d70c1de9eb3"
   },
   "outputs": [],
   "source": [
    "# device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device is\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7z7FjDKoF0O"
   },
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D27L1A7JoF0P"
   },
   "outputs": [],
   "source": [
    "#TODO description de VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9cScWKXoF0Q"
   },
   "source": [
    "Dans un premier temps, nous chargeons le modèle VGG pré-entraîné afin d'évaluer notre implémentation sur un réseau dont les poids sont déjà optimisés:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vjteuMJoF0R"
   },
   "outputs": [],
   "source": [
    "cnn = models.vgg19(pretrained=True).features.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfD3U8Q6oF0R"
   },
   "source": [
    "## Reconstruction d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFXXm3KGoF0S"
   },
   "source": [
    "He *et al.* définissent une manière de reconstruire une image $x_0$ à l'aide d'une couche $l$ d'un réseau de neurones et d'une pré-image (synthétique) $x$. Etant donnée la fonction $F^l$ représentant la couche $l$, on définit l'erreur de contenu pour la couche $l$ par l'erreur quadratique moyenne entre les représentations des deux images par cette couche:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_\\text{content}(x, x_0, l) := \\dfrac{1}{2N^l M^l}\\left\\|F^l(x)-F^l(x_0)\\right\\|_2^2,\n",
    "$$\n",
    "\n",
    "où la dimension spatiale $M^l$ et le nombre de filtres $N^l$ sont les dimensions de la feature map: $F^l(x)\\in \\mathbb{R}^{N^l\\times M^l}.$\n",
    "\n",
    "La pré-image $x$ est ensuite améliorée par rapport à cette perte par descente de gradient en suivant l'algorithme L-BFGS.\n",
    "\n",
    "Notons que nous avons omis la pondération $\\omega_l$ de cette fonction de perte, qui n'est pas utilisée pour cette tâche par He *et al.*. Nous détaillons et justifions nos autres modifications de cette fonction de perte dans nos commentaires sur ranVGG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKdx-hrEoF0T"
   },
   "outputs": [],
   "source": [
    "def content_loss(cnn: nn.Module, layer_outputs: \"list[torch.Tensor]\", target_outputs: \"list[torch.Tensor]\", synthetic_image: \"torch.Tensor\"):\n",
    "    \"\"\"Calcule la loss de contenu entre la représentation de l'image \n",
    "    synthétique et celle de l'image cible.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cnn : nn.Module\n",
    "        Modèle à utiliser pour la reconstruction.\n",
    "    layer_output_ : list[torch.Tensor]\n",
    "        Liste qui contient les sorties des couches considérées pour la \n",
    "        représentation après la forward pass sur cnn \n",
    "        (cf. utils.register_model_hooks).\n",
    "    target_outputs : list[torch.Tensor]\n",
    "        Représentation de l'image cible.\n",
    "    synthetic_image : torch.Tensor\n",
    "        Image synthétique.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss: torch.Tensor\n",
    "    \"\"\"\n",
    "\n",
    "    # step 1: forward-propagate and get the layer output from the mutable\n",
    "    cnn(synthetic_image)\n",
    "\n",
    "    # step 2: compute the loss\n",
    "    loss = sum(\n",
    "        (F.mse_loss(synth_out, target_out)\n",
    "         for synth_out, target_out in zip(layer_outputs, target_outputs)),\n",
    "        start=torch.tensor(0)\n",
    "    )\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gatys *et al.* utilisent la première couche convolutive et les 4 premières couches maxpool pour la génération de textures, ce qui motive notre choix de couches utilisées par défaut pour reconstruire l'image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUQdtcSwoF0U"
   },
   "outputs": [],
   "source": [
    "# couches utilisées par défaut pour la reconstruction:\n",
    "TARGET_LAYERS = [1, 4, 9, 18, 27]  # 1rst Conv2d (after ReLU) and MaxPool2d\n",
    "\n",
    "\n",
    "def reconstruct_image(cnn: nn.Sequential, target_image: torch.Tensor, target_layers: \"list[int]\" = TARGET_LAYERS, n_steps: int = 5, synth_std: float = 1, logging=False, progressbar=True, synth_init: torch.Tensor = None) -> \"tuple[torch.Tensor, torch.Tensor, list[float]]\":\n",
    "    \"\"\"Reconstruit une image source en inversant sa représentation.\n",
    "    L'image synthétisée est intialisée par un bruit blanc gaussien.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cnn : nn.Sequential\n",
    "        Réseau de neurones à utiliser. \n",
    "    target_image : torch.Tensor\n",
    "        Image source à reconstruire.\n",
    "    target_layers : list[int], default: `TARGET_LAYERS`\n",
    "        Couches du cnn à utiliser pour reconstruire l'image.\n",
    "    n_steps : int, default: 5\n",
    "        Nombre de passes de LBFGS à effectuer. \n",
    "    synth_std : float, default: 1\n",
    "        Ecart-type du bruit blanc gaussien.\n",
    "    logging : bool, default: False\n",
    "        Si True, remplit loss_history.\n",
    "    progressbar : bool, default: True\n",
    "        Si True, affiche une barre de progression.\n",
    "    synth_init : torch.Tensor, default: None\n",
    "        Tenseur à utiliser pour l'intialisation de l'image synthétisée à la \n",
    "        place d'un bruit blanc gaussien.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    synthetic_image, final_loss, loss_history\n",
    "    synthetic_image : torch.Tensor\n",
    "        Image synthétisée.\n",
    "    final_loss : torch.Tensor\n",
    "        Perte de reconstruction associée à l'image synthétisée.\n",
    "    loss_history : list[float]\n",
    "        Historique des pertes. Est non vide si et seulement si logging est True.\n",
    "    \"\"\"\n",
    "    if synth_init is not None:\n",
    "        synthetic_image = synth_init.detach().clone()\n",
    "        synthetic_image.requires_grad_()\n",
    "    else:\n",
    "        # on initialise la pré-image avec un bruit blanc:\n",
    "        synthetic_image = utils.normal_like(target_image, synth_std)\n",
    "\n",
    "    layer_outputs, handles = utils.register_model_hooks(\n",
    "        cnn,\n",
    "        target_layers\n",
    "    )\n",
    "\n",
    "    # le réseau ne va pas être modifié, donc on peut calculer la cible une fois pour toutes:\n",
    "    cnn(target_image)\n",
    "    # on considère la cible comme une vérité terrain:\n",
    "    target_outputs = [t.detach().clone() for t in layer_outputs]\n",
    "\n",
    "    optimizer = optim.LBFGS(\n",
    "        [synthetic_image],\n",
    "        max_iter=20\n",
    "    )\n",
    "\n",
    "    loss_history = []\n",
    "    if progressbar:\n",
    "        iterator = trange(n_steps, desc=\"Image reconstruction\", unit=\"step\")\n",
    "    else:\n",
    "        iterator = range(n_steps)\n",
    "    for _ in iterator:\n",
    "        def closure():\n",
    "            # zero out the gradients, else they'll accumulate in synthetic_image.grad\n",
    "            optimizer.zero_grad()\n",
    "            loss = content_loss(\n",
    "                cnn,\n",
    "                layer_outputs,\n",
    "                target_outputs,\n",
    "                synthetic_image\n",
    "            )\n",
    "            loss.backward()  # backpropagate the loss to the input\n",
    "            if logging:\n",
    "                loss_history.append(loss.item())\n",
    "            return loss\n",
    "        optimizer.step(closure)\n",
    "        if progressbar and logging:\n",
    "            iterator.set_postfix(content_loss=loss_history[-1])\n",
    "\n",
    "    final_loss = content_loss(cnn, layer_outputs, target_outputs, synthetic_image)\n",
    "\n",
    "    utils.unregister_model_hooks(handles)\n",
    "\n",
    "    return synthetic_image, final_loss, loss_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSCosScyoF0W"
   },
   "source": [
    "Testons la reconstruction d'image sur le modèle VGG pré-entraîné:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sYyugPUoF0X"
   },
   "outputs": [],
   "source": [
    "input_image_name = \"briques.png\"\n",
    "img_size = 256\n",
    "\n",
    "target_image = utils.prep_img(input_image_name, img_size).to(device)\n",
    "synthetic_image, loss, loss_history = reconstruct_image(\n",
    "    cnn,\n",
    "    target_image,\n",
    "    n_steps=100,\n",
    "    logging=True\n",
    ")\n",
    "\n",
    "fig, _ = plt.subplots(1, 2, figsize=(15, 10))\n",
    "fig.axes[0].imshow(utils.to_pil(target_image))\n",
    "fig.axes[0].set_title(\"Original\")\n",
    "fig.axes[1].imshow(utils.to_pil(synthetic_image))\n",
    "fig.axes[1].set_title(\"Reconstruction\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lYnuF6foF0Y"
   },
   "source": [
    "Nous arrivons bien à reconstruire l'image d'origine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLog4Y-loF0Y"
   },
   "outputs": [],
   "source": [
    "# plot loss history\n",
    "fig, _ = plt.subplots(1, 1, figsize=(15, 10))\n",
    "fig.axes[0].plot(loss_history)\n",
    "fig.axes[0].set_xlabel(\"L-BFGS iterations\")\n",
    "fig.axes[0].set_ylabel(\"Content loss\")\n",
    "fig.axes[0].set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOaXtoIJoF0Y"
   },
   "source": [
    "Au vu de la courbe ci-dessus, la fonction de perte semble converger pour VGG autour de 100 itérations de L-BGFS; nous avons donc choisi `n_steps = 5` par défaut, ce qui correspond bien à 100 itérations de L-BFGS (`optim.LBFGS` effectue 20 itérations par étape)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqW7E0wNoF0Z"
   },
   "source": [
    "### Construction de ranVGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO décrire le mode de construction, pseudo-entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_layer_(cnn: nn.Sequential, target_image: torch.Tensor, layer_idx: int):\n",
    "    \"\"\"Normalise les poids de la couche convolutive de manière à ce que l'activation\n",
    "    moyenne soit 1.\n",
    "    \"\"\"\n",
    "    activation_idx = layer_idx + 1\n",
    "    layer_output_, handle_ = utils.register_model_hooks(\n",
    "        cnn,\n",
    "        [activation_idx]\n",
    "    )\n",
    "    cnn(target_image)\n",
    "    with torch.no_grad():\n",
    "        mean_activation = torch.mean(layer_output_[0]).item()\n",
    "        cnn[layer_idx].weight.copy_(cnn[layer_idx].weight / mean_activation)\n",
    "        cnn[layer_idx].bias.copy_(cnn[layer_idx].bias / mean_activation)\n",
    "    utils.unregister_model_hooks(handle_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cf4HjHpuoF0Z"
   },
   "outputs": [],
   "source": [
    "def build_ranvgg_(cnn: nn.Sequential, target_image: torch.Tensor, target_layers: \"list[int]\" = TARGET_LAYERS, n_samples: int = 5, n_steps: int = 5, synth_std: float = 1, normalize=True):\n",
    "    # on utilise la même image synthétique pour comparer tous les échantillons:\n",
    "    synthetic_image = utils.normal_like(target_image, synth_std)\n",
    "    cnn.requires_grad_(False)  # on empêche le modèle d'apprendre\n",
    "    # on entraîne les couches convolutives:\n",
    "    layers_to_build = [\n",
    "        idx for idx, layer in enumerate(cnn) if isinstance(layer, nn.Conv2d)\n",
    "    ]\n",
    "    for layer_idx in tqdm(layers_to_build, desc=\"Building ranVGG\", unit=\"layer\"):\n",
    "        # on vise la couche d'activation (ReLU) pour la reconstruction d'image:\n",
    "        activation_idx = layer_idx + 1\n",
    "        best_layer = None\n",
    "        best_loss = float(\"inf\")\n",
    "\n",
    "        with trange(n_samples, leave=False, unit=\"sample\") as pbar:\n",
    "            for _ in pbar:\n",
    "                # on tire une nouvelle couche convolutive:\n",
    "                cnn[layer_idx] = utils.conv2D_like(cnn[layer_idx])\n",
    "                # on lui donne un écart-type de 0.015:\n",
    "                utils.randomize_layer_(cnn[layer_idx])\n",
    "                if normalize:\n",
    "                    # on normalise les poids de la couche:\n",
    "                    normalize_layer_(cnn, target_image, layer_idx)\n",
    "\n",
    "                # on évalue la qualité de notre couche:\n",
    "                _, loss, _ = reconstruct_image(\n",
    "                    cnn,\n",
    "                    target_image,\n",
    "                    target_layers,  # TODO maybe build a list of current target layers instead ?\n",
    "                    synth_init=synthetic_image,\n",
    "                    n_steps=n_steps,\n",
    "                    progressbar=False\n",
    "                )\n",
    "                # on ne garde pas le gradient de la loss:\n",
    "                loss = loss.item()\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    best_layer = cnn[layer_idx]\n",
    "                    pbar.set_postfix(best_loss=best_loss)\n",
    "        cnn[layer_idx] = best_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "4f36e9885769465c9ab06d37d32b6581",
      "b6fea858c50544db814bc2b5401614e2",
      "a8cf1dcdcc4c425f9f1bc2981f448dc0",
      "b0f566c9e6f54ccc8b3cf7a88772cba9",
      "8fecfd351f2a4b678df5d69bbcb6f46c",
      "7c0dbf51134e424fa9bae3266154926d",
      "7149af7f6a524245b48fa2a25e58b83f",
      "200600cd2cd4418b9eab2169724ca113",
      "10abc0c2232049a1b25fbbc7a7bb75d3",
      "77e62cd11c284ae9b5ec29ae85cfca36",
      "a9c31a6eaf4742bea2989e0af3e8a9b6",
      "d134f4d1240a440085ceb6782861abc6",
      "d4622ad06396407b82a9a721e00bab6c",
      "67d046273c954e54b447c9c0a26f918b",
      "6ac88bf320f0413287ac5401fa9e6f64",
      "ff43d4a1f09741ec8908753610937608",
      "3a6ad5eb940846ed8f150cf0a84ba45c",
      "602378b3ff0f4c228c35f144e014c6e1",
      "96737ab497724eb4ab156d93da90c9a6",
      "702d11cd88524f9cbafb1e3ae18cf45a",
      "fc6ffecf68104e268fd9b0b285d37da9",
      "4a01e7876e0a4ce79d59a6d5047cfc43",
      "f09a6d7a4c9f4408b0d177bd3181b4e2",
      "45dc844ccf5c42a8af3a768401068420",
      "cf923ad9c6184464905fdcca61d2d24b",
      "2e65bc95e57e46d1ac5867df061ae3be",
      "16c5390959034b08b45829ac725021fd",
      "e1801b9c32494df9b09f9b87977f60d8",
      "84bbcaaf0e82435985ef6c89e8b33578",
      "e92f4982b4d04be183c39f7cde8c86d5",
      "f0c67be370be4a5d9e725adee1ef12c0",
      "6fc036ca0251491cb80ceeff4e9cdecb",
      "a1c4a9e42a054d789969929a51f44edd",
      "92e33113ce684defa6b2c84994da61cf",
      "7527bcf229a54f1ebbb5ae0733528df0",
      "5b2dc9dfcf0a4a4ba70e12dd54472a0e",
      "3faec4ba728544059fbe10c2dccf5dcd",
      "16e492ef26a143038ff0ae8206e6c6c8",
      "8845825bd8264ce8b417f9ebc6f19c9c",
      "156d1b5d027647b8b0ed7d6119c9f699",
      "6d797473642549c0ae49de1f0e5fca71",
      "f928b74213504bf08eddeed8638b17f6",
      "b5f6aa6ffc1c4521bca799413aff96cc",
      "ad23bd95d30949048f676864a286ee25",
      "ecb394f28d25480e815d32235ec4a91f",
      "4868613d3e95423b971cb31ed93a6bc6",
      "a81d9fd6fc484027b21bf21bef3b0f9c",
      "4ec325f2be774a7b93e8870a43debbf7",
      "716dc3a345c040928539b2bf68e8721f",
      "ccb906482a4d4a79af9c8d5a5456db9d",
      "7f7598dfb58f4addaf89336f3155561a",
      "ad7cbc01d8654f4eb2c6b7e87730a49f",
      "3c2453cac6974f108dae9c8f225d4a91",
      "4e18b9c63a0e4f309a48f3f71461812d",
      "f0bdc92b3c7145b18335f4904f37356c",
      "7f2353f0f7054de9b5ebff7a9f60e30c",
      "64f055d0541d41a0a568eef293a441ba",
      "73643a580c824425aa322875922e10f0",
      "ed890af6acb443a6a0735776f4b240ac",
      "04f48be9ab614767889e67949f4cec70",
      "11759d8249c24b3cb30f48790773bbbe",
      "080785ab1cd44c10baaf3e338908cf38",
      "9b1d0360ef73480cbaf2a4f924929f1c",
      "c80fc48cbf474827b3ce42da9f99a441",
      "4a09f69ffcd14acb8c9e974e9ce1418c",
      "a63ec60c06ab47eca36b3ad259ba0b77",
      "15981e02c7784f5f981a21b986cf12a0",
      "f501786f26be4c62a08d876313bdbb4a",
      "cf219852e9d94edc887a51ac0b708b8d",
      "13c064e77c664282999df388310733e6",
      "d1f723e635ce406b93f8940861009496",
      "7f037a27c6af4647bade95670ab36040",
      "2844743490994c2e8e059d77bdd98af5",
      "92ae7a83466f4eafb4ca2889c02dfc38",
      "5c99d11a2c6b4fc8ae3471366774fd17",
      "f5377718485c4e6a98c5643a65cde36a",
      "5490994bcd1a4b61bd91eb25921b8265",
      "67aca89e49754799b7e1ed89c6f83c29",
      "712b314cb34c41968e1bb5a6b6cfd59d",
      "c3d0bdef1fdd480084f5875c9b371fa4",
      "e361d71190d4437c821fc733b0483b46",
      "dd44c782457847d98fcb6191384f7249",
      "d25cb9362a10436599e1c2906e571da7",
      "2f6fbda446b744f5bb44135a20704937",
      "6a4bcc5b4be94f9481c07da5e5fe3b1d",
      "135ff595b76441839f88aeaa7da98451",
      "d267ab55d808428e828562dbd82e6a0b",
      "312a6dccef374da1acc11b97bacbb6c1",
      "7ff4b37a171e4ec2b6fdfc0e53cb5cdd",
      "89d323833d424bcb8efcaeb3bfe2daa5",
      "3109e3d83aaa442b90e78da25ea3dab4",
      "690825df27be4b44a45fe9b80d1fd09f",
      "b30c7dbcb781469da8417a582ae564fd",
      "1b79a3f34816429ba908c942338cc5b7",
      "dc84abb6af464fcd977c6b068cda8c63",
      "becf469c9c4f4a68b27e52246eeef7b0",
      "d272e3b75e8c45209506737238a677b9",
      "b4f50857671741f0b7b5df8852e07159",
      "1009c225eb394e7587d5234c6806292f",
      "725a78cdb7da454ea62f2bdd1bf4658a",
      "7ec2f8f05d33408195db9d0adab77ffd",
      "55e75c5926f14419b65adb46d3bbe7b4",
      "13d5c0aa5a4b4e96883a08d1f03a0e06",
      "a4ef8514752d4b23b22b850ec76976d3",
      "87930c47e5cc4a8e8afe6f832840d2d3",
      "da7fc797e89e490e9bdcd8ac503b08f7",
      "c7045d6370af4acc88405e95aaa12e31",
      "05a748996c61453c814b21c85f8bd4e7",
      "f4ffb3e92e594bacb7b19e1b4a9a39b1",
      "e62151f6424d46f5aa157901d8327191",
      "714e8004dac3405ebc40a44cae063716",
      "b4ffe634d7d641d3af8b1d4884b5c102",
      "25ea022c5233461e9f9838226c32866b",
      "0d5a6773050642ecbe057867bed9944e",
      "6f33510ab41d40b0aa02f5f6d48ec8d3",
      "d1d158fbb8614d7caba380ffb69e39b6",
      "7985332ffaa648cf9bdc9d1e77843f56",
      "3d813a69fbc94726a96d0535b2846414",
      "2297c11ce3394591b8bef91e972bb30f",
      "339c72623775420e8d395cf816188d58",
      "af4966ca78404a36b9476a6aa9ac29f4",
      "3736e0b1bfa04a3185abeebacda045d6",
      "3f173115df764ac489ba8531c43927cc",
      "96aebc8401b94aa08b8771bdd86ba3cd",
      "16ba2304744f42e1ab11f5c03e007e6c",
      "fb851f26e9e1476ba04eaa9c79e76a55",
      "7d169e3c925e4faaa403f1eb640da417",
      "aab19ecad724415abacf37892337380e",
      "42752914f35f43f896afdd51b52c4c2e",
      "af1347964f5545d684cc4086de181023",
      "aba1bfe28d5f4dfbb412f86a1a3f1442",
      "f37b5e56f44b4ed885af898138e3a8ee",
      "4cd7001e2c8349db8834a9444f681f58",
      "16cdda2af2f2432aa7a2b90a1193ae94",
      "057d31c6cca447bb9ed5fbfb15bdca52",
      "27c73c74ec9a4720a11d89636f3feab7",
      "9b6924970b5c4b8d9833581c32bea610",
      "b46dd589da0b406a9420529945c374f5",
      "9c06d66a64054a34a901c2645d478df4",
      "eacfeb5dfee34a6b9590932c5e8efd84",
      "383437f19c2440a2831a7fa5fe627aea",
      "ca89c396635247539fe42abc0b4f575a",
      "b5fd171e977649b59712ddd689d86ceb",
      "d7609c197ae249a7bbd48e4aabfee027",
      "9f7fcba24b54471db6f651facc7e4d22",
      "751518eaa6614e58a2f782e6e55952b2",
      "de499279dcb94cea85dd8f84684547b5",
      "35f537c38ff949f3885fba53e0d00bc4",
      "ada71f805ae649a09d4cb4c9a4cd95d5",
      "a87f2baddd7140e7b04691a3d5518763",
      "fdbb27f075164baf85c3a99418b9a176",
      "f7b0799a037f499c92af73c0e1b6ed37",
      "5e1fb84aee8040078492ba5c71f66203",
      "a103cd448b8a4a6885db40bdd985979d",
      "bf91f7aa235d4119a491509e0ae5c057",
      "20cb91e9632f410f8d174b9534fc77be",
      "2f8356bb680b4571a41c46eb22617c5d",
      "9059bf30c1e644ad8849553299764037",
      "f1b948be668947b4b0bd8d4dd4ec7cff",
      "3d2bfc0a1cbb43778d5dd7ed8d51e35c",
      "a3baf59524be42e495406b37e2c829ec",
      "0c993a1855ea4061b52fcea9fa39c99c",
      "d8dce65297dc4bacb58a2a0a6cd66539",
      "1f97919825b34b329c7a3d7fe7997869",
      "e1e1e14733f142a1a2e70276a26f3d05",
      "8ada8cffc19840d692a29502a7d5c841",
      "17ac63a5b67a4e21a2bdce5918dec905",
      "7942796c25d34de08a5958d683d2e2aa",
      "6be158968053408d938fb013c47fd21e",
      "b4c0f7b71d544018be7fb0740933e0c3",
      "b95e26f7f7e64feeb6bd33ccda3bfa2f",
      "36e30f985af94c1890b5dc30183fe539",
      "b1cddb8f845c453f9f3906b514e15b3a",
      "99fcfa2118344cbebcb62750c6259094",
      "f406f3e7cdc7412ab37061ef54c8b532",
      "87ab4bc02536430b914e714a64c57fec",
      "aef8ac22c77f4d6bba93d7556e50472c",
      "a94506d66d2041a198f69b42532fbfbe",
      "dee663d7e86a423ebf78f998756927f2",
      "ab5a6c53f9e94da5bb42dc473a968504",
      "d7f21223e290401880952775d06ed4b4",
      "d600c83e17fc4fdcb7851c5e5b60eb1b",
      "7b65838dd70d4633840b4ea937686a6a",
      "b6588e73f70142b5806050eb8811498d",
      "df47c5dc75d4456ab5f170151bde582b",
      "729fd36b7008405badbf639d4e20a4db",
      "a49f2f8f733740928f0fb8a6951041a8"
     ]
    },
    "id": "V2EA4LKmoF0Z",
    "outputId": "50d54fa3-2dec-4284-df6e-f2aaaac0f941"
   },
   "outputs": [],
   "source": [
    "# construction de ranVGG\n",
    "input_image_name = \"briques.png\"\n",
    "img_size = 256\n",
    "\n",
    "target_image = utils.prep_img(input_image_name, img_size).to(device)\n",
    "ranvgg = models.vgg19(pretrained=False).features.to(device).eval()\n",
    "build_ranvgg_(ranvgg, target_image, n_steps=5, n_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428,
     "referenced_widgets": [
      "547c1a49c1ff4a9181d0c2729cd9cc4f",
      "fda18cb02e664894b6ea1506fabc920f",
      "953456a335d34e8facf8593e7b708fde",
      "fa019d86e16b449eac4730dc747a07c9",
      "aa997d0d2582469c8db6853165a3f0bb",
      "f73478617ee54ce184e773847bc6034e",
      "6d5b24f9e6e84e9498f3f27629053803",
      "806c1ab379654cc6af4437862a2ab335",
      "add11168847c437292e2f22a06e41f8c",
      "0033183044e34530964fb4fdd9f19cb1",
      "2cef15f125ef48798a575004467e5056"
     ]
    },
    "id": "buEbSFYGoF0a",
    "outputId": "949a8b04-f663-4c89-fe78-f5554ef816ca"
   },
   "outputs": [],
   "source": [
    "# test de ranVGG\n",
    "\n",
    "synthetic_image, loss, loss_history = reconstruct_image(\n",
    "    ranvgg,\n",
    "    target_image,\n",
    "    n_steps=20,\n",
    "    logging=True\n",
    ")\n",
    "\n",
    "fig, _ = plt.subplots(1, 2, figsize=(15, 10))\n",
    "fig.axes[0].imshow(utils.to_pil(target_image))\n",
    "fig.axes[0].set_title(\"Original\")\n",
    "fig.axes[1].imshow(utils.to_pil(synthetic_image))\n",
    "fig.axes[1].set_title(\"Reconstruction\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSJMY6EHoF0a"
   },
   "outputs": [],
   "source": [
    "# plot loss history\n",
    "fig, _ = plt.subplots(1, 1, figsize=(15, 10))\n",
    "fig.axes[0].plot(loss_history)\n",
    "fig.axes[0].set_xlabel(\"L-BFGS iterations\")\n",
    "fig.axes[0].set_ylabel(\"Content loss\")\n",
    "fig.axes[0].set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps, on remarque que l'image est bien reconstruite par ranVGG. Dans un second temps, on peut constater que contrairement à He *et al.*, nous avons utilisé toutes les couches `TARGET_LAYERS` (rappelées dans le code ci-dessous) pour calculer la fonction de perte. La raison est que malgré la normalisation de chaque couche, on observe le problème de vanishing gradient si on n'utilise que les couches profondes (comme le font He *et al.*) pour calculer la fonction de perte; les réseaux modernes évitent ce problème en utilisant des couches résiduelles (cf. [ResNet](https://arxiv.org/abs/1512.03385)). Pour le gradient, cela revient à sommer les gradients de différentes couches; VGG n'ayant pas de couche résiduelle, notre approche est donc de sommer les pertes de différentes couches pour constituer notre perte de contenu sur le réseau de neurones tout entier:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_\\text{content}(x_0,x)\n",
    ":=\\sum_{l\\in \\texttt{TARGET\\_LAYERS}} \\mathcal{L}_\\text{content}(x_0,x, l) \n",
    "= \\sum_{l\\in \\texttt{TARGET\\_LAYERS}} \\dfrac{1}{2N^l M^l}\\left\\|F^l(x)-F^l(x_0)\\right\\|_2^2,\n",
    "$$\n",
    "\n",
    "On peut tester ce raisonnement en essayant de reconstruire l'image à partir d'une couche à la fois:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LAYERS = [1, 4, 9, 18, 27]  # 1rst Conv2d (after ReLU) and MaxPool2d\n",
    "LAYER_NAMES = [\"conv1\", \"pool1\", \"pool2\", \"pool3\", \"pool4\"]\n",
    "\n",
    "fig, axes = plt.subplots(len(TARGET_LAYERS) + 1, 2, figsize=(20, 40))\n",
    "axes[0, 0].imshow(utils.to_pil(target_image))\n",
    "axes[0, 0].set_title(\"Original\")\n",
    "for idx, (layer_idx, layer_name) in enumerate(zip(TARGET_LAYERS, LAYER_NAMES)):\n",
    "    synthetic_image, loss, loss_history = reconstruct_image(\n",
    "        ranvgg,\n",
    "        target_image,\n",
    "        target_layers=[layer_idx],\n",
    "        n_steps=20,\n",
    "        logging=True\n",
    "    )\n",
    "    axes[idx + 1, 0].imshow(utils.to_pil(synthetic_image))\n",
    "    axes[idx + 1, 0].set_title(f\"Reconstruction ({layer_name})    Loss = {loss.item()}\")\n",
    "    axes[idx + 1, 1].plot(loss_history)\n",
    "    axes[idx + 1, 1].set_xlabel(\"L-BFGS iterations\")\n",
    "    axes[idx + 1, 1].set_ylabel(\"Content loss\")\n",
    "    axes[idx + 1, 1].set_xscale('log')\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que cette reconstuction a bien convergé dans tous les cas, mais se dégrade au fur et a mesure qu'on augmente en profondeur dans le réseau.\n",
    "\n",
    "On peut également noter que L-BFGS a une condition d'arrêt qui lui permet d'économiser des itérations si la fonction de perte ou son gradient sont suffisamment faibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une autre expérience intéressante est de regarder l'effet de la normalisation des couches sur le rendu final (cf `normalize_layer_` plus haut); cette normalisation, introduite par Gatys *et al.*, s'assure que:\n",
    "\n",
    "$$\n",
    "\\dfrac{1}{WHC}\\sum_{i=1}^W \\sum_{j=1}^H \\sum_{k=1}^C F^l(x_0) = 1\n",
    "$$\n",
    "\n",
    "Regardons les résultats de reconstruction si l'on omet cette normalisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construction de ranVGG\n",
    "input_image_name = \"briques.png\"\n",
    "img_size = 256\n",
    "\n",
    "target_image = utils.prep_img(input_image_name, img_size).to(device)\n",
    "unnormalized_ranvgg = models.vgg19(pretrained=False).features.to(device).eval()\n",
    "build_ranvgg_(unnormalized_ranvgg, target_image, n_steps=5, n_samples=5, normalize=False)\n",
    "\n",
    "# test de ranVGG\n",
    "\n",
    "synthetic_image, loss, loss_history = reconstruct_image(\n",
    "    unnormalized_ranvgg,\n",
    "    target_image,\n",
    "    n_steps=20,\n",
    "    logging=True\n",
    ")\n",
    "\n",
    "fig, _ = plt.subplots(1, 2, figsize=(15, 10))\n",
    "fig.axes[0].imshow(utils.to_pil(target_image))\n",
    "fig.axes[0].set_title(\"Original\")\n",
    "fig.axes[1].imshow(utils.to_pil(synthetic_image))\n",
    "fig.axes[1].set_title(\"Reconstruction\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bum-XXR3oF0d"
   },
   "source": [
    "### singleVGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous testons ici une approche proposée par Pierrick Chatillon, qui consiste à remplacer le pseudo-entraînement de He *et al.* par une descente de gradient par rapport à la perte de reconstruction, l'idée étant que l'on veut que notre couche puisse plus efficacement reconstruire l'image à partir d'un bruit blanc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUnJ-C4_oF0d"
   },
   "outputs": [],
   "source": [
    "def build_singlevgg_(cnn: nn.Module, target_image: torch.Tensor, target_layers: \"list[int]\" = TARGET_LAYERS, n_epochs: int = 20, n_steps: int = 5, synth_std: float = 1):\n",
    "    cnn.requires_grad_(False)  # on empêche le modèle d'apprendre\n",
    "    # on entraîne les couches convolutives:\n",
    "    layers_to_build = [\n",
    "        idx for idx, layer in enumerate(cnn) if isinstance(layer, nn.Conv2d)\n",
    "    ]\n",
    "    for layer_idx in tqdm(layers_to_build, desc=\"Building ranVGG\", unit=\"layer\"):\n",
    "        conv_layer = cnn[layer_idx]\n",
    "        normalize_layer_(cnn, target_image, layer_idx)\n",
    "        # on entraîne chaque layer individuellement:\n",
    "        conv_layer.requires_grad_(True)\n",
    "        optimizer = optim.Adam(conv_layer.parameters(), lr=0.0001)\n",
    "        # on vise la couche d'activation (ReLU) pour la reconstruction d'image:\n",
    "        activation_idx = layer_idx + 1\n",
    "        with trange(n_epochs, leave=False, unit=\"epoch\") as pbar:\n",
    "            for _ in pbar:\n",
    "                # on évalue la qualité de notre couche:\n",
    "                # NB: l'image synthétique change à chaque epoch\n",
    "                _, loss, _ = reconstruct_image(\n",
    "                    cnn,\n",
    "                    target_image,\n",
    "                    target_layers=target_layers,\n",
    "                    n_steps=n_steps,\n",
    "                    progressbar=False\n",
    "                )\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                normalize_layer_(cnn, target_image, layer_idx)\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "        conv_layer.requires_grad_(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ExVPW_CLoF0e"
   },
   "outputs": [],
   "source": [
    "# construction de singleVGG\n",
    "input_image_name = \"briques.png\"\n",
    "img_size = 256\n",
    "\n",
    "target_image = utils.prep_img(input_image_name, img_size).to(device)\n",
    "singlevgg = models.vgg19(pretrained=False).features.to(device).eval()\n",
    "build_singlevgg_(singlevgg, target_image, n_steps=5, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428,
     "referenced_widgets": [
      "0c8f8cb6494c43c3aa68edea289001df",
      "329b59792de04bd3bcf89870a89333b3",
      "e4d827de7e2f4d55a99385d0c69c9b26",
      "655800c5fda846fa9e622fb2614222cb",
      "d539dea69e704d2c9db2efc85c8dfb53",
      "18dfc5f26a9c4582be2ecc0a3f5d584f",
      "bc5fa9a5487d4c3f8ea20d36b3e6eb69",
      "7fd8ea9d31c14396b687c9930ce78993",
      "2f29681e007b4d7eb700935044701ec4",
      "63acb57d3df646f0b7082bf6c4d30122",
      "6021f452f1c246fd81ef558cdf529036"
     ]
    },
    "id": "Tqi0nBkCoF0e",
    "outputId": "fb32bb71-f214-494d-f003-4ae149356748"
   },
   "outputs": [],
   "source": [
    "# test de singleVGG\n",
    "\n",
    "synthetic_image, loss, loss_history = reconstruct_image(\n",
    "    singlevgg,\n",
    "    target_image,\n",
    "    n_steps=100,\n",
    "    logging=True\n",
    ")\n",
    "\n",
    "fig, _ = plt.subplots(1, 2, figsize=(15, 10))\n",
    "fig.axes[0].imshow(utils.to_pil(target_image))\n",
    "fig.axes[0].set_title(\"Original\")\n",
    "fig.axes[1].imshow(utils.to_pil(synthetic_image))\n",
    "fig.axes[1].set_title(\"Reconstruction\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "KECfu_JVoF0e",
    "outputId": "e3725954-07ca-426e-a4e8-d1819676200c"
   },
   "outputs": [],
   "source": [
    "# plot loss history\n",
    "fig, _ = plt.subplots(1, 1, figsize=(15, 10))\n",
    "fig.axes[0].plot(loss_history)\n",
    "fig.axes[0].set_xlabel(\"L-BFGS iterations\")\n",
    "fig.axes[0].set_ylabel(\"Content loss\")\n",
    "fig.axes[0].set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO comments on performance, training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZvHiksIoF0f"
   },
   "outputs": [],
   "source": [
    "#TODO stuff below here is for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FpvJ1dyuoF0f"
   },
   "outputs": [],
   "source": [
    "def gramm(tnsr: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Computes Gram matrix for the input batch tensor.\n",
    "    Args: tnsr (torch.Tensor): input tensor of the Size([B, C, H, W]).\n",
    "    Returns:  G (torch.Tensor): output tensor of the Size([B, C, C]).\n",
    "    \"\"\"\n",
    "    b, c, h, w = tnsr.size()\n",
    "    F = tnsr.view(b, c, h * w)\n",
    "    G = torch.bmm(F, F.transpose(1, 2))\n",
    "    G.div_(h * w)\n",
    "    return G\n",
    "\n",
    "\n",
    "def gram_loss(input: torch.Tensor, gramm_target: torch.Tensor, weight: float = 1.0):\n",
    "    \"\"\"Computes the MSE loss between the Gram matrix of the input and the target\n",
    "    Gram matrix. \n",
    "    \"\"\"\n",
    "    loss = weight * F.mse_loss(gramm(input), gramm_target)\n",
    "    return loss\n",
    "\n",
    "\n",
    "#TODO define texture_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1W0q95-oF0g"
   },
   "outputs": [],
   "source": [
    "# layers to use in the texture synthesis:\n",
    "TARGET_LAYERS = [1, 4, 9, 18, 27]  # 1rst Conv2d (after ReLU) and MaxPool2d\n",
    "LAYER_NAMES = [\"conv1\", \"pool1\", \"pool2\", \"pool3\", \"pool4\"]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "rapport.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ec098f3f8c662b53cb495a99f3bdf670fa1052aa811a9729b1f28e0384e8235b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
