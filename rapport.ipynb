{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthèse de textures par réseau convolutif (filtres aléatoires)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch images\n",
    "texture_imgnames = [\"bois.png\", \"briques.png\", \"mur.png\",\n",
    "                    \"tissu.png\", \"nuages.png\", \"pebbles.jpg\", \"wall1003.png\"]\n",
    "#TODO use urllib instead \n",
    "#import wget\n",
    "for fname in texture_imgnames:\n",
    "    os.system(\"wget -c https://www.idpoisson.fr/galerne/mva/\" + fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device is\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ranVGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO description de VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps, nous chargeons le modèle VGG pré-entraîné afin d'évaluer notre implémentation sur un réseau dont les poids sont déjà optimisés:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.vgg19(pretrained=True).features.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO description théorique  de la content loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(cnn: nn.Module, layer_output_: \"list[torch.Tensor]\", target_out: torch.Tensor, synthetic_image: \"torch.Tensor\", weighing_factor: float = None):\n",
    "    # uses the layer_output variable to get the output of the target layer\n",
    "    # assumes correctly batched input (ie bchw dimensions)\n",
    "    # assumes target of shape chw\n",
    "    # make sure to un/register hooks before/after content_loss, using relu output\n",
    "    # suitable to use inside a closure (see https://pytorch.org/docs/stable/optim.html)\n",
    "    # TODO docstring\n",
    "\n",
    "    # step 1: forward-propagate and get the layer output from the mutable\n",
    "    cnn(synthetic_image)\n",
    "    synth_out = layer_output_[0] # add batch dimension\n",
    "    \n",
    "    # step 2: compute the loss\n",
    "    n_feature_maps, feature_height, feature_width = synth_out.shape\n",
    "    loss = F.mse_loss(synth_out, target_out)\n",
    "\n",
    "    if weighing_factor is not None:\n",
    "        loss *= weighing_factor\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO description de la reconstruction d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_image(cnn: nn.Module, target_image: torch.Tensor, target_layer_idx: int, n_steps: int = 20, synth_std: float = 0.5, logging=False, progressbar=True, synth_init: torch.Tensor = None):\n",
    "    # return reconstructed image and final loss\n",
    "    # TODO docstring\n",
    "\n",
    "    if synth_init is not None:\n",
    "        synthetic_image = synth_init.detach().clone()\n",
    "        synthetic_image.requires_grad_()\n",
    "    else:\n",
    "        # on initialise la pré-image avec un bruit blanc:\n",
    "        synthetic_image = utils.normal_like(target_image, synth_std)\n",
    "\n",
    "    layer_output_, handles = utils.register_model_hooks(\n",
    "        cnn,\n",
    "        [target_layer_idx]\n",
    "    )\n",
    "\n",
    "    # le réseau ne va pas être modifié, donc on peut calculer la cible une fois pour toutes:\n",
    "    cnn(target_image)\n",
    "    # on considère la cible comme une vérité terrain:\n",
    "    target_out = layer_output_[0].detach().clone()\n",
    "\n",
    "    optimizer = optim.LBFGS([synthetic_image], max_iter=20)\n",
    "\n",
    "    loss_history = []\n",
    "\n",
    "    if progressbar:\n",
    "        iterator = trange(n_steps, desc=\"Image reconstruction\", unit=\"step\")\n",
    "    else:\n",
    "        iterator = range(n_steps)\n",
    "    for _ in iterator:\n",
    "        def closure():\n",
    "            # zero out the gradients, else they'll accumulate in synthetic_image.grad\n",
    "            optimizer.zero_grad()\n",
    "            loss = content_loss(cnn, layer_output_,\n",
    "                                target_out, synthetic_image)\n",
    "            loss.backward()  # backpropagate the loss to the input\n",
    "            if logging:\n",
    "                loss_history.append(loss.item())\n",
    "            return loss\n",
    "        optimizer.step(closure)\n",
    "        if progressbar and logging:\n",
    "            iterator.set_postfix(content_loss=loss_history[-1])\n",
    "\n",
    "    final_loss = content_loss(cnn, layer_output_, target_out, synthetic_image)\n",
    "\n",
    "    utils.unregister_model_hooks(handles)\n",
    "\n",
    "    return synthetic_image, final_loss, loss_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons la reconstruction d'image; He *et al.* comparent leurs résultats aux sorties des couches de pooling de VGG, et nous allons donc utiliser la couche pooling3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_name = \"briques.png\"\n",
    "img_size = 256\n",
    "target_layer = 18  # pool3\n",
    "\n",
    "target_image = utils.prep_img(input_image_name, img_size).to(device)\n",
    "synthetic_image, loss, loss_history = reconstruct_image(\n",
    "    cnn,\n",
    "    target_image,\n",
    "    target_layer,\n",
    "    n_steps=100,\n",
    "    logging=True\n",
    ")\n",
    "\n",
    "fig, _ = plt.subplots(1, 2, figsize=(15, 10))\n",
    "fig.axes[0].imshow(utils.to_pil(target_image))\n",
    "fig.axes[0].set_title(\"Original\")\n",
    "fig.axes[1].imshow(utils.to_pil(synthetic_image))\n",
    "fig.axes[1].set_title(\"Reconstruction\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous arrivons bien à reconstruire l'image d'origine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss history\n",
    "fig, _ = plt.subplots(1, 1, figsize=(15, 10))\n",
    "fig.axes[0].plot(loss_history)\n",
    "fig.axes[0].set_xlabel(\"L-BFGS iterations\")\n",
    "fig.axes[0].set_ylabel(\"Content loss\")\n",
    "fig.axes[0].set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au vu de la courbe ci-dessus, la fonction de perte semble converger pour VGG entre 100 et 1000 itérations de L-BGFS; nous avons donc choisi `n_steps = 20` par défaut, ce qui correspond à 400 itérations de L-BFGS (`optim.LBFGS` effectue par 20 itérations par étape)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction de ranVGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ranvgg_(cnn: nn.Module, target_image: torch.Tensor, n_samples: int = 20, n_steps: int = 20, synth_std: float = 0.5):\n",
    "    # remplacement des poids du modèle par un bruit blanc:\n",
    "    cnn.requires_grad_(False)  # on empêche le modèle d'apprendre\n",
    "    # on entraîne les couches convolutives:\n",
    "    layers_to_build = [\n",
    "        idx for idx, layer in enumerate(cnn) if isinstance(layer, nn.Conv2d)\n",
    "    ]\n",
    "    for layer_idx in tqdm(layers_to_build, desc=\"Building ranVGG\", unit=\"layer\"):\n",
    "        # on vise la couche d'activation (ReLU) pour la reconstruction d'image:\n",
    "        activation_idx = layer_idx + 1\n",
    "        conv_layer = cnn[layer_idx]\n",
    "        best_weight = None\n",
    "        best_bias = None\n",
    "        best_loss = float(\"inf\")\n",
    "        # on utilise la même image synthétique pour comparer tous les échantillons:\n",
    "        synthetic_image = utils.normal_like(target_image, synth_std)\n",
    "        with trange(n_samples, leave=False, unit=\"sample\") as pbar:\n",
    "            for _ in pbar:\n",
    "                utils.randomize_layer_(conv_layer)\n",
    "                # on évalue la qualité de notre couche:\n",
    "                _, loss, _ = reconstruct_image(\n",
    "                    cnn,\n",
    "                    target_image,\n",
    "                    activation_idx,\n",
    "                    synth_init=synthetic_image,\n",
    "                    n_steps=n_steps,\n",
    "                    progressbar=False\n",
    "                )\n",
    "                # on ne garde que le gradient de la loss:\n",
    "                loss = loss.item()\n",
    "\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    best_weight = conv_layer.weight.detach().clone()\n",
    "                    best_bias = conv_layer.bias.detach().clone()\n",
    "                    pbar.set_postfix(best_loss=best_loss)\n",
    "        conv_layer.weight.copy_(best_weight)\n",
    "        conv_layer.bias.copy_(best_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO does not work properly :(\n",
    "# construction de ranVGG\n",
    "input_image_name = \"briques.png\"\n",
    "img_size = 256\n",
    "\n",
    "target_image = utils.prep_img(input_image_name, img_size).to(device)\n",
    "ranvgg = models.vgg19(pretrained=False).features.to(device).eval()\n",
    "build_ranvgg_(ranvgg, target_image, n_steps=40, n_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test de ranVGG\n",
    "target_layer = 18  # pool3\n",
    "\n",
    "synthetic_image, loss, loss_history = reconstruct_image(\n",
    "    ranvgg,\n",
    "    target_image,\n",
    "    target_layer,\n",
    "    n_steps=100,\n",
    "    logging=True\n",
    ")\n",
    "\n",
    "fig, _ = plt.subplots(1, 2, figsize=(15, 10))\n",
    "fig.axes[0].imshow(utils.to_pil(target_image))\n",
    "fig.axes[0].set_title(\"Original\")\n",
    "fig.axes[1].imshow(utils.to_pil(synthetic_image))\n",
    "fig.axes[1].set_title(\"Reconstruction\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss history\n",
    "fig, _ = plt.subplots(1, 1, figsize=(15, 10))\n",
    "fig.axes[0].plot(loss_history)\n",
    "fig.axes[0].set_xlabel(\"L-BFGS iterations\")\n",
    "fig.axes[0].set_ylabel(\"Content loss\")\n",
    "fig.axes[0].set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO stuff below here is for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gramm(tnsr: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Computes Gram matrix for the input batch tensor.\n",
    "    Args: tnsr (torch.Tensor): input tensor of the Size([B, C, H, W]).\n",
    "    Returns:  G (torch.Tensor): output tensor of the Size([B, C, C]).\n",
    "    \"\"\"\n",
    "    b, c, h, w = tnsr.size()\n",
    "    F = tnsr.view(b, c, h * w)\n",
    "    G = torch.bmm(F, F.transpose(1, 2))\n",
    "    G.div_(h * w)\n",
    "    return G\n",
    "\n",
    "\n",
    "def gram_loss(input: torch.Tensor, gramm_target: torch.Tensor, weight: float = 1.0):\n",
    "    \"\"\"Computes the MSE loss between the Gram matrix of the input and the target\n",
    "    Gram matrix. \n",
    "    \"\"\"\n",
    "    loss = weight * F.mse_loss(gramm(input), gramm_target)\n",
    "    return loss\n",
    "\n",
    "\n",
    "#TODO define texture_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers to use in the texture synthesis:\n",
    "TARGET_LAYERS = [1, 4, 9, 18, 27]  # 1rst Conv2d (after ReLU) and MaxPool2d\n",
    "LAYER_NAMES = [\"conv1\", \"pool1\", \"pool2\", \"pool3\", \"pool4\"]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec098f3f8c662b53cb495a99f3bdf670fa1052aa811a9729b1f28e0384e8235b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
