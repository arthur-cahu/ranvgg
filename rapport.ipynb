{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthèse de textures par réseau convolutif (filtres aléatoires)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch images\n",
    "texture_imgnames = [\"bois.png\", \"briques.png\", \"mur.png\",\n",
    "                    \"tissu.png\", \"nuages.png\", \"pebbles.jpg\", \"wall1003.png\"]\n",
    "#TODO use urllib instead \n",
    "#import wget\n",
    "for fname in texture_imgnames:\n",
    "    os.system(\"wget -c https://www.idpoisson.fr/galerne/mva/\" + fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device is\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ranVGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO description de VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps, nous chargeons le modèle VGG pré-entraîné afin d'évaluer notre implémentation sur un réseau dont les poids sont déjà optimisés:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.vgg19(pretrained=True).features.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO description théorique  de la content loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(cnn: nn.Module, layer_output_: \"list[torch.Tensor]\", target_out: torch.Tensor, synthetic_image: \"torch.Tensor\", weighing_factor: float = None):\n",
    "    \"\"\"Calcule la loss de contenu entre la représentation de l'image \n",
    "    synthétique et celle de l'image cible.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cnn : nn.Module\n",
    "        Modèle à utiliser pour la reconstruction.\n",
    "    layer_output_ : list[torch.Tensor]\n",
    "        Liste qui contient la sortie de la couche considérée pour la \n",
    "        représentation après la forward pass sur cnn \n",
    "        (cf utils.register_model_hooks).\n",
    "    target_out : torch.Tensor\n",
    "        Représentation de l'image cible.\n",
    "    synthetic_image : torch.Tensor\n",
    "        Image synthétique. \n",
    "    weighing_factor : float, default: None\n",
    "        Facteur par lequel multiplier la perte.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss: torch.Tensor\n",
    "    \"\"\"\n",
    "    # uses the layer_output variable to get the output of the target layer\n",
    "    # assumes correctly batched input (ie bchw dimensions)\n",
    "    # assumes target of shape chw\n",
    "    # make sure to un/register hooks before/after content_loss, using relu output\n",
    "    # suitable to use inside a closure (see https://pytorch.org/docs/stable/optim.html)\n",
    "    # TODO docstring\n",
    "\n",
    "    # step 1: forward-propagate and get the layer output from the mutable\n",
    "    cnn(synthetic_image)\n",
    "    synth_out = layer_output_[0] # add batch dimension\n",
    "    \n",
    "    # step 2: compute the loss\n",
    "    n_feature_maps, feature_height, feature_width = synth_out.shape\n",
    "    loss = F.mse_loss(synth_out, target_out)\n",
    "\n",
    "    if weighing_factor is not None:\n",
    "        loss *= weighing_factor\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO description de la reconstruction d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_image(cnn: nn.Sequential, target_image: torch.Tensor, target_layer_idx: int, n_steps: int = 20, synth_std: float = 0.5, logging=False, progressbar=True, synth_init: torch.Tensor = None) -> \"tuple[torch.Tensor, torch.Tensor, list[float]]\":\n",
    "    \"\"\"Reconstruit une image source en inversant sa représentation.\n",
    "    L'image synthétisée est intialisée par un bruit blanc gaussien.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cnn : nn.Sequential\n",
    "        Réseau de neurones à utiliser. \n",
    "    target_image : torch.Tensor\n",
    "        Image source à reconstruire.\n",
    "    target_layer_idx : int\n",
    "        Couche du cnn à utiliser pour reconstruire l'image.\n",
    "    n_steps : int, default: 20\n",
    "        Nombre de passes de LBFGS à effectuer. \n",
    "    synth_std : float, default: 0.5\n",
    "        Ecart-type du bruit blanc gaussien.\n",
    "    logging : bool, default: False\n",
    "        Si True, remplit loss_history.\n",
    "    progressbar : bool, default: True\n",
    "        Si True, affiche une barre de progression.\n",
    "    synth_init : torch.Tensor, default: None\n",
    "        Tenseur à utiliser pour l'intialisation de l'image synthétisée à la \n",
    "        place d'un bruit blanc gaussien.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    synthetic_image, final_loss, loss_history\n",
    "    synthetic_image : torch.Tensor\n",
    "        Image synthétisée.\n",
    "    final_loss : torch.Tensor\n",
    "        Perte de reconstruction associée à l'image synthétisée.\n",
    "    loss_history : list[float]\n",
    "        Historique des pertes. Est non vide si et seulement si logging est True.\n",
    "    \"\"\"\n",
    "    if synth_init is not None:\n",
    "        synthetic_image = synth_init.detach().clone()\n",
    "        synthetic_image.requires_grad_()\n",
    "    else:\n",
    "        # on initialise la pré-image avec un bruit blanc:\n",
    "        synthetic_image = utils.normal_like(target_image, synth_std)\n",
    "\n",
    "    layer_output_, handles = utils.register_model_hooks(\n",
    "        cnn,\n",
    "        [target_layer_idx]\n",
    "    )\n",
    "\n",
    "    # le réseau ne va pas être modifié, donc on peut calculer la cible une fois pour toutes:\n",
    "    cnn(target_image)\n",
    "    # on considère la cible comme une vérité terrain:\n",
    "    target_out = layer_output_[0].detach().clone()\n",
    "\n",
    "    # on met la tolérance à 0 pour forcer l'algorithme à effectuer les 20 itérations:\n",
    "    optimizer = optim.LBFGS(\n",
    "        [synthetic_image],\n",
    "        max_iter=20,\n",
    "        tolerance_change=0,\n",
    "        tolerance_grad=0\n",
    "    )\n",
    "\n",
    "    loss_history = []\n",
    "    if progressbar:\n",
    "        iterator = trange(n_steps, desc=\"Image reconstruction\", unit=\"step\")\n",
    "    else:\n",
    "        iterator = range(n_steps)\n",
    "    for _ in iterator:\n",
    "        def closure():\n",
    "            # zero out the gradients, else they'll accumulate in synthetic_image.grad\n",
    "            optimizer.zero_grad()\n",
    "            loss = content_loss(\n",
    "                cnn,\n",
    "                layer_output_,\n",
    "                target_out,\n",
    "                synthetic_image\n",
    "            )\n",
    "            loss.backward()  # backpropagate the loss to the input\n",
    "            if logging:\n",
    "                loss_history.append(loss.item())\n",
    "            return loss\n",
    "        optimizer.step(closure)\n",
    "        if progressbar and logging:\n",
    "            iterator.set_postfix(content_loss=loss_history[-1])\n",
    "\n",
    "    final_loss = content_loss(cnn, layer_output_, target_out, synthetic_image)\n",
    "\n",
    "    utils.unregister_model_hooks(handles)\n",
    "\n",
    "    return synthetic_image, final_loss, loss_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons la reconstruction d'image; He *et al.* comparent leurs résultats aux sorties des couches de pooling de VGG, et nous allons donc utiliser la couche pooling3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_name = \"briques.png\"\n",
    "img_size = 256\n",
    "target_layer = 18  # pool3\n",
    "\n",
    "target_image = utils.prep_img(input_image_name, img_size).to(device)\n",
    "synthetic_image, loss, loss_history = reconstruct_image(\n",
    "    cnn,\n",
    "    target_image,\n",
    "    target_layer,\n",
    "    n_steps=100,\n",
    "    logging=True\n",
    ")\n",
    "\n",
    "fig, _ = plt.subplots(1, 2, figsize=(15, 10))\n",
    "fig.axes[0].imshow(utils.to_pil(target_image))\n",
    "fig.axes[0].set_title(\"Original\")\n",
    "fig.axes[1].imshow(utils.to_pil(synthetic_image))\n",
    "fig.axes[1].set_title(\"Reconstruction\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous arrivons bien à reconstruire l'image d'origine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss history\n",
    "fig, _ = plt.subplots(1, 1, figsize=(15, 10))\n",
    "fig.axes[0].plot(loss_history)\n",
    "fig.axes[0].set_xlabel(\"L-BFGS iterations\")\n",
    "fig.axes[0].set_ylabel(\"Content loss\")\n",
    "fig.axes[0].set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au vu de la courbe ci-dessus, la fonction de perte semble converger pour VGG autour de 100 itérations de L-BGFS; nous avons donc choisi `n_steps = 5` par défaut, ce qui correspond bien à 100 itérations de L-BFGS (`optim.LBFGS` effectue par 20 itérations par étape)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction de ranVGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ranvgg_(cnn: nn.Module, target_image: torch.Tensor, n_samples: int = 20, n_steps: int = 5, synth_std: float = 1):\n",
    "    cnn.requires_grad_(False)  # on empêche le modèle d'apprendre\n",
    "    # on entraîne les couches convolutives:\n",
    "    layers_to_build = [\n",
    "        idx for idx, layer in enumerate(cnn) if isinstance(layer, nn.Conv2d)\n",
    "    ]\n",
    "    for layer_idx in tqdm(layers_to_build, desc=\"Building ranVGG\", unit=\"layer\"):\n",
    "        # on vise la couche d'activation (ReLU) pour la reconstruction d'image:\n",
    "        activation_idx = layer_idx + 1\n",
    "        best_layer = None\n",
    "        best_loss = float(\"inf\")\n",
    "        # on utilise la même image synthétique pour comparer tous les échantillons:\n",
    "        synthetic_image = utils.normal_like(target_image, synth_std)\n",
    "        with trange(n_samples, leave=False, unit=\"sample\") as pbar:\n",
    "            for _ in pbar:\n",
    "                # on tire une nouvelle couche convolutive:\n",
    "                cnn[layer_idx] = utils.conv2D_like(cnn[layer_idx])\n",
    "                # on évalue la qualité de notre couche:\n",
    "                _, loss, _ = reconstruct_image(\n",
    "                    cnn,\n",
    "                    target_image,\n",
    "                    activation_idx,\n",
    "                    synth_init=synthetic_image,\n",
    "                    n_steps=n_steps,\n",
    "                    progressbar=False\n",
    "                )\n",
    "                # on ne garde pas le gradient de la loss:\n",
    "                loss = loss.item()\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    best_layer = cnn[layer_idx]\n",
    "                    pbar.set_postfix(best_loss=best_loss)\n",
    "        cnn[layer_idx] = best_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construction de ranVGG\n",
    "input_image_name = \"briques.png\"\n",
    "img_size = 256\n",
    "\n",
    "target_image = utils.prep_img(input_image_name, img_size).to(device)\n",
    "ranvgg = models.vgg19(pretrained=False).features.to(device).eval()\n",
    "build_ranvgg_(ranvgg, target_image, n_steps=5, n_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test de ranVGG\n",
    "target_layer = 18  # pool3\n",
    "\n",
    "synthetic_image, loss, loss_history = reconstruct_image(\n",
    "    ranvgg,\n",
    "    target_image,\n",
    "    target_layer,\n",
    "    n_steps=100,\n",
    "    logging=True\n",
    ")\n",
    "\n",
    "fig, _ = plt.subplots(1, 2, figsize=(15, 10))\n",
    "fig.axes[0].imshow(utils.to_pil(target_image))\n",
    "fig.axes[0].set_title(\"Original\")\n",
    "fig.axes[1].imshow(utils.to_pil(synthetic_image))\n",
    "fig.axes[1].set_title(\"Reconstruction\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss history\n",
    "fig, _ = plt.subplots(1, 1, figsize=(15, 10))\n",
    "fig.axes[0].plot(loss_history)\n",
    "fig.axes[0].set_xlabel(\"L-BFGS iterations\")\n",
    "fig.axes[0].set_ylabel(\"Content loss\")\n",
    "fig.axes[0].set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### singleVGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_singlevgg_(cnn: nn.Module, target_image: torch.Tensor, n_epochs: int = 20, n_steps: int = 5, synth_std: float = 1):\n",
    "    cnn.requires_grad_(False)  # on empêche le modèle d'apprendre\n",
    "    # on entraîne les couches convolutives:\n",
    "    layers_to_build = [\n",
    "        idx for idx, layer in enumerate(cnn) if isinstance(layer, nn.Conv2d)\n",
    "    ]\n",
    "    for layer_idx in tqdm(layers_to_build, desc=\"Building ranVGG\", unit=\"layer\"):\n",
    "        conv_layer = cnn[layer_idx]\n",
    "        conv_layer.requires_grad_(True) # on entraîne chaque layer individuellement\n",
    "        optimizer = optim.Adam(conv_layer.parameters(), lr=0.0001)\n",
    "        # on vise la couche d'activation (ReLU) pour la reconstruction d'image:\n",
    "        activation_idx = layer_idx + 1\n",
    "        with trange(n_epochs, leave=False, unit=\"epoch\") as pbar:\n",
    "            for _ in pbar:\n",
    "                # on évalue la qualité de notre couche:\n",
    "                # NB: l'image initiale change à chaque epoch\n",
    "                _, loss, _ = reconstruct_image(\n",
    "                    cnn,\n",
    "                    target_image,\n",
    "                    activation_idx,\n",
    "                    n_steps=n_steps,\n",
    "                    progressbar=False\n",
    "                )\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "        conv_layer.requires_grad_(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construction de singleVGG\n",
    "input_image_name = \"briques.png\"\n",
    "img_size = 256\n",
    "\n",
    "target_image = utils.prep_img(input_image_name, img_size).to(device)\n",
    "singlevgg = models.vgg19(pretrained=False).features.to(device).eval()\n",
    "build_singlevgg_(singlevgg, target_image, n_steps=5, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test de singleVGG\n",
    "target_layer = 18  # pool3\n",
    "\n",
    "synthetic_image, loss, loss_history = reconstruct_image(\n",
    "    singlevgg,\n",
    "    target_image,\n",
    "    target_layer,\n",
    "    n_steps=100,\n",
    "    logging=True\n",
    ")\n",
    "\n",
    "fig, _ = plt.subplots(1, 2, figsize=(15, 10))\n",
    "fig.axes[0].imshow(utils.to_pil(target_image))\n",
    "fig.axes[0].set_title(\"Original\")\n",
    "fig.axes[1].imshow(utils.to_pil(synthetic_image))\n",
    "fig.axes[1].set_title(\"Reconstruction\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss history\n",
    "fig, _ = plt.subplots(1, 1, figsize=(15, 10))\n",
    "fig.axes[0].plot(loss_history)\n",
    "fig.axes[0].set_xlabel(\"L-BFGS iterations\")\n",
    "fig.axes[0].set_ylabel(\"Content loss\")\n",
    "fig.axes[0].set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO stuff below here is for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gramm(tnsr: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Computes Gram matrix for the input batch tensor.\n",
    "    Args: tnsr (torch.Tensor): input tensor of the Size([B, C, H, W]).\n",
    "    Returns:  G (torch.Tensor): output tensor of the Size([B, C, C]).\n",
    "    \"\"\"\n",
    "    b, c, h, w = tnsr.size()\n",
    "    F = tnsr.view(b, c, h * w)\n",
    "    G = torch.bmm(F, F.transpose(1, 2))\n",
    "    G.div_(h * w)\n",
    "    return G\n",
    "\n",
    "\n",
    "def gram_loss(input: torch.Tensor, gramm_target: torch.Tensor, weight: float = 1.0):\n",
    "    \"\"\"Computes the MSE loss between the Gram matrix of the input and the target\n",
    "    Gram matrix. \n",
    "    \"\"\"\n",
    "    loss = weight * F.mse_loss(gramm(input), gramm_target)\n",
    "    return loss\n",
    "\n",
    "\n",
    "#TODO define texture_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers to use in the texture synthesis:\n",
    "TARGET_LAYERS = [1, 4, 9, 18, 27]  # 1rst Conv2d (after ReLU) and MaxPool2d\n",
    "LAYER_NAMES = [\"conv1\", \"pool1\", \"pool2\", \"pool3\", \"pool4\"]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec098f3f8c662b53cb495a99f3bdf670fa1052aa811a9729b1f28e0384e8235b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
